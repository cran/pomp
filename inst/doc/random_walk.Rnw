\documentclass[10pt,reqno,final]{amsart}
%\VignetteIndexEntry{Introduction to pomp by example}
\usepackage{times}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{graphicx}

\title[Examples in \texttt{pomp}]{Introduction to \texttt{pomp} by example}

\author[A. A. King]{Aaron A. King}

\address{A. A. King, Departments of Ecology \& Evolutionary Biology and Mathematics, University of Michigan, Ann Arbor, Michigan 48109-1048 USA}

\email{kingaa at umich dot edu} 

\urladdr{http://www.umich.edu/\~{}kingaa}

\date{\today}

\newcommand\code[1]{\texttt{#1}}

\begin{document}

\SweaveOpts{echo=T,results=verbatim,print=F,eps=F,pdf=T}

\maketitle

\section{A first example: a two-dimensional random walk.}

<<echo=F,results=hide>>=
  options(keep.source=TRUE,width=60)
  library(pomp)
@ 

In order to specify a partially-observed Markov process, we must define the process model and the measurement model.
In particular, we will need to be able to simulate from and compute the p.d.f. of both models.
The following function will simulate the process model.
The documentation (\code{?pomp}) spells out the specifications for this function.
<<>>=
  rw.rprocess <- function (xstart, times, params, ...) { 
    ## this function simulates two independent random walks with intensities s1, s2
    nsims <- ncol(params)
    ntimes <- length(times)
    dt <- diff(times)
    x <- array(0,dim=c(2,nsims,ntimes))
    rownames(x) <- rownames(xstart)
    noise.sds <- params[c('s1','s2'),]
    x[,,1] <- xstart
    for (j in 2:ntimes) {
      ## we are mimicking a continuous-time process, so the increments have SD ~ sqrt(dt)
      ## note that we do not have to assume that 'times' are equally spaced
      x[,,j] <- rnorm(n=2*nsims,mean=x[,,j-1],sd=noise.sds*dt[j-1])
    }
    x
  }
@ 
Some methods will require the probability density of a given state transition.
The function \code{dprocess} will evaluate this for a sequences of state transitions.
<<>>=
  rw.dprocess <- function (x, times, params, log = FALSE, ...) { 
    ## given a sequence of consecutive states in 'x', this function computes the p.d.f.
    nsims <- ncol(params)
    ntimes <- length(times)
    dt <- diff(times)
    d <- array(0,dim=c(2,nsims,ntimes-1))
    noise.sds <- params[c('s1','s2'),]
    for (j in 2:ntimes)
      d[,,j-1] <- dnorm(x[,,j]-x[,,j-1],mean=0,sd=noise.sds*dt[j-1],log=TRUE)
    if (log) {
      apply(d,c(2,3),sum)
    } else {
      exp(apply(d,c(2,3),sum))
    }
  }
@ 
Now we specify the function that will simulate the measurement process.
Again, the documentation spells out how.
<<>>=
  bvnorm.rmeasure <- function (x, times, params, ...) {
    ## noisy observations of the two walks with common noise SD 'tau'
    nsims <- dim(x)[2]
    ntimes <- dim(x)[3]
    y <- array(0,dim=c(2,nsims,ntimes))
    rownames(y) <- c('y1','y2')
    for (j in 1:nsims) {
      for (k in 1:ntimes) {
	y[,j,k] <- rnorm(2,mean=x[,j,k],sd=params['tau',j])
      }
    }
    y
  }
@ 
Finally, we have to specify how to evaluate the likelihood of an observation given the underlying state.
<<>>=
  bvnorm.dmeasure <- function (y, x, times, params, log = FALSE, ...) {
    ## noisy observations of the two walks with common noise SD 'tau'
    d1 <- dnorm(
                x=y['y1',],
                mean=x['x1',,],
                sd=params['tau',],
                log=TRUE
                )
    d2 <- dnorm(
                x=y['y2',],
                mean=x['x2',,],
                sd=params['tau',],
                log=TRUE
                )
    if (log) {
      d1+d2
    } else {
      exp(d1+d2)
    }
  }
@ 
The following builds a \code{pomp} object called \code{rw2}.
<<>>=
rw2 <- pomp(
            rprocess = rw.rprocess,
            dprocess = rw.dprocess,
            rmeasure = bvnorm.rmeasure,
            dmeasure = bvnorm.dmeasure,
            times=1:100,
            data=rbind(
              y1=rep(0,100),
              y2=rep(0,100)
              ),
            t0=0,
            useless=23
            )
@ 

Now we'll specify some parameters and initial states.
<<print=T>>=
p <- rbind(s1=c(2,2,3),s2=c(0.1,1,2),tau=c(1,5,0),x1.0=c(0,0,5),x2.0=c(0,0,0))
p
@ 
Each column is a different initial state or parameter vector.
Note that we must use rownames!
Notice also that we parameterize the initial states by means of parameters with names ending in ``.0''.

When we defined \code{rw2}, the data were all missing.
We can generate simulated data by:
<<>>=
examples <- simulate(rw2,params=p)
rw2 <- examples[[1]]
@ 
By default \code{simulate} will generate a list of new \code{pomp} objects.
It can also be used to obtain the simulated state and/or measurement trajectories:
<<>>=
x <- simulate(rw2,params=p,states=T)
y <- simulate(rw2,params=p,obs=T)
y <- simulate(rw2,params=p,obs=T,states=T,nsim=10)
@ 

A \code{plot} method exists for \code{pomp} objects (Fig.~\ref{fig:random_walk}).

\begin{figure}
<<fig=T>>=
plot(rw2)
@ 
\caption{A \code{plot} method exists for \code{pomp} objects.}
\label{fig:random_walk}
\end{figure}

Access to the individual components of the \code{pomp} object is available by means of a few \emph{methods}.
To extract the data and the observation times, use \code{data.array} and \code{time}, respectively:
<<>>=
x <- data.array(rw2)
t <- time(rw2)
@ 
It's also possible to coerce a \code{pomp} object to a \code{data.frame}:
<<>>=
z <- as(rw2,'data.frame')
names(z)
@ 
To run the process model, users should use \code{simulate} with the \code{states=T} option.
Lower-level access to the process model is available via the \code{rprocess} method:
<<>>=
x0 <- init.state(rw2,params=p)
x <- rprocess(rw2,xstart=x0,times=0:100,params=p)
@ 
Note that we use the low-level \code{init.state} method to initialize the unobserved state.
Similarly, low-level access to the measurement-model simulator can be had through \code{rmeasure}:
<<>>=
y <- rmeasure(rw2,x=x,times=0:100,params=p)
@ 
Access to the process-model p.d.f. is available via \code{dprocess}:
<<>>=
log(dprocess(rw2,x[,,6:11],times=5:10,params=p))
dprocess(rw2,x[,,6:11],times=5:10,params=p,log=T)
@ 
Note that \code{dprocess} returns a matrix: 
the rows correspond to independent simulations, the columns to distinct state transitions.
The measurement-model p.d.f. is accessed via the \code{dmeasure} method, which like \code{dprocess}, returns a matrix.
The rows correspond to independent simulations, the columns to distinct times.
<<>>=
dmeasure(rw2,y=y[,1,1:4],x=x[,,1:4,drop=F],times=time(rw2)[1:4],p)
dmeasure(rw2,y=y[,2,1:4],x=x[,,1:4,drop=F],times=time(rw2)[1:4],p)
log(dmeasure(rw2,y=y[,3,1:4],x=x[,,1:4,drop=F],times=time(rw2)[1:4],p))
dmeasure(rw2,y=y[,3,1:4],x=x[,,1:4,drop=F],times=time(rw2)[1:4],p,log=T)
@ 

\section{A two-dimensional Ornstein-Uhlenbeck process.}

To keep things simple, we will study a discrete-time process.
The tricks below will continue to be useful even in the case of a continuous-time process, but the computational effort will be greater.
The unobserved Ornstein-Uhlenbeck (OU) process $X_{t}\in\mathbb{R}^2$ satisfies
\begin{equation*}
  X_{t} = A\,X_{t-1}+\xi_{t}.
\end{equation*}
The observation process is
\begin{equation*}
  Y_{t} = B\,X_{t}+\varepsilon_{t}.
\end{equation*}
In these equations, $A$ and and $B$ are 2$\times$2 constant matrices; $\xi_{t}$ and $\varepsilon_{t}$ are mutually-independent families of i.i.d. bivariate normal random variables.
We let $\sigma\sigma^T$ be the variance-covariance matrix of $\xi_{t}$, where $\sigma$ is lower-triangular;
likewise, we let $\tau\tau^T$ be that of $\varepsilon_{t}$.

We build the \code{pomp} object by specifying the three basic elements.
The process model simulator and density functions:
<<>>=
  ou2.rprocess <- function (xstart, times, params, ...) { 
    ## this function simulates two discrete-time OU processes
    nsims <- ncol(xstart)
    ntimes <- length(times)
    alpha <- array(params[c('alpha.1','alpha.2','alpha.3','alpha.4'),],dim=c(2,2,nsims))
    sigma <- array(params[c('sigma.1','sigma.2','sigma.2','sigma.3'),],dim=c(2,2,nsims))
    sigma[1,2,] <- 0
    x <- array(0,dim=c(2,nsims,ntimes))
    rownames(x) <- rownames(xstart)
    x[,,1] <- xstart
    for (k in 1:nsims) {
      for (j in 2:ntimes) {
	x[,k,j] <- alpha[,,k]%*%x[,k,j-1]+sigma[,,k]%*%rnorm(2)
      }
    }
    x
  }
@ 
<<>>=
  ou2.dprocess <- function (x, times, params, log = FALSE, ...) { 
    ## this function simulates two discrete-time OU processes
    nsims <- ncol(x)
    ntimes <- length(times)
    alpha <- array(params[c('alpha.1','alpha.2','alpha.3','alpha.4'),],dim=c(2,2,nsims))
    sigma <- array(params[c('sigma.1','sigma.2','sigma.2','sigma.3'),],dim=c(2,2,nsims))
    sigma[1,2,] <- 0
    d <- array(0,dim=c(nsims,ntimes-1))
    for (k in 1:nsims) {
      for (j in 2:ntimes) {
        z <- forwardsolve(sigma[,,k],x[,k,j]-alpha[,,k]%*%x[,k,j-1])
        if (log) {
	  d[k,j-1] <- sum(dnorm(z,mean=0,sd=1,log=TRUE))
	} else {
	  d[k,j-1] <- exp(sum(dnorm(z,mean=0,sd=1,log=TRUE)))
	}
      }
    }
    d
  }
@ 
The measurement model is the same as that for the random walk example above.
We build the \code{pomp} object:
<<>>=
ou2 <- pomp( 
	    times=seq(1,100),
	    data=rbind(
	      y1=rep(0,100),
	      y2=rep(0,100)
	      ),
	    t0=0,
	    rprocess = ou2.rprocess,
	    dprocess = ou2.dprocess,
	    rmeasure = bvnorm.rmeasure,
	    dmeasure = bvnorm.dmeasure
	    )
@

Now we'll specify the ``true'' parameters and initial states.
<<print=T>>=
p <- c(
       alpha.1=0.9,alpha.2=0,alpha.3=0,alpha.4=0.99,
       sigma.1=1,sigma.2=0,sigma.3=2,
       tau=1,x1.0=50,x2.0=-50
       )
@ 
As before, we'll fill in the missing values with simulated data.
<<>>=
 tic <- Sys.time()
 ou2 <- simulate(ou2,params=p,nsim=1000)
 toc <- Sys.time()
 print(toc-tic)
 ou2 <- ou2[[1]]
@ 

Let's make sure everything works.
<<>>=
x0 <- init.state(ou2,params=p)
x <- rprocess(ou2,xstart=as.matrix(x0),times=c(0,time(ou2)),params=as.matrix(p))
@ 
<<>>=
y <- rmeasure(ou2,x=x[,,-1,drop=F],times=time(ou2),params=as.matrix(p))
@ 
<<>>=
dprocess(ou2,x[,,36:41,drop=F],times=time(ou2)[35:40],params=as.matrix(p))
dmeasure(ou2,y=y[,1,1:4],x=x[,,2:5,drop=F],times=time(ou2)[1:4],params=as.matrix(p))
@ 

\section{Linking in compiled code for computational efficiency.}

The functions we've just written are (relatively) easy to read, but they will be slow to evaluate because, being written in R, they must be interpreted.
Since many of the methods we will use require us to simulate the process and/or measurement models many times, it is a good idea to translate these codes into a compiled language.
The package includes some C codes that were written to implement the OU example.
Read the source (file `ou2.c') for details.

\subsection{The \texttt{.C} interface}

<<>>=
  ou2.rprocess <- function (xstart, times, params, ...) {
    nvar <- nrow(xstart)
    npar <- nrow(params)
    nrep <- ncol(xstart)
    ntimes <- length(times)
    ## get indices of the various parameters in the 'params' matrix
    parindex <- match(
		      c('alpha.1','alpha.2','alpha.3','alpha.4','sigma.1','sigma.2','sigma.3'),
		      rownames(params)
		      )-1      # C uses zero-based indexing!
    array(
	  .C("ou2_adv",
	     X = double(nvar*nrep*ntimes),
	     xstart = as.double(xstart),
	     par = as.double(params),
	     times = as.double(times),
	     n = as.integer(c(nvar,npar,nrep,ntimes)),
	     parindex = as.integer(parindex),
	     DUP = FALSE,
	     NAOK = TRUE,
	     PACKAGE = "pomp"
	     )$X,
	  dim=c(nvar,nrep,ntimes),
	  dimnames=list(rownames(xstart),NULL,NULL)
	  )
  }

bvnorm.dmeasure <- function (y, x, times, params, log = TRUE, ...) {
  measindex <- match(c("tau"),rownames(params))-1
  nvar <- dim(x)[1]
  nrep <- dim(x)[2]
  ntimes <- dim(x)[3]
  npar <- nrow(params)
  nobs <- 2
  ## since the system is autonomous, no need to keep track of time
  array(
	.C(
           "normal_dmeasure",
           n = as.integer(c(nvar,npar,nrep,ntimes,nobs)), 
           X = as.double(x),
           par = as.double(params),
           index = as.integer(measindex),
           Y = as.double(y),
           f = double(nrep*ntimes),
           give_log = as.integer(log),
           DUP = FALSE,
           NAOK = TRUE,
           PACKAGE = "pomp"
           )$f,
        dim=c(nrep,ntimes)
        )
}

bvnorm.rmeasure <- function (x, times, params, ...) {
nvar <- dim(x)[1]
nrep <- dim(x)[2]
ntimes <- dim(x)[3]
npar <- dim(params)[1]
nobs <- 2
measindex <- match(c("tau"),rownames(params))-1
array(
      .C(
         "normal_rmeasure",
         n = as.integer(c(nvar,npar,nrep,ntimes,nobs)),
         X = as.double(x),
         par = as.double(params),
         index = as.integer(measindex),
         obs = double(nobs*nrep*ntimes),
         DUP = FALSE,
         NAOK = TRUE,
         PACKAGE = "pomp"
         )$obs,
      dim=c(nobs,nrep,ntimes),
      dimnames=list(c('y1','y2'),NULL,NULL)
      )
}

ou2 <- pomp( 
	    times=seq(1,100),
	    data=rbind(
	      y1=rep(0,100),
	      y2=rep(0,100)
	      ),
	    t0=0,
	    rprocess = ou2.rprocess,
	    dprocess = ou2.dprocess,
	    rmeasure = bvnorm.rmeasure,
	    dmeasure = bvnorm.dmeasure
	    )
@ 

<<>>=
 tic <- Sys.time()
 ou2 <- simulate(ou2,params=p,nsim=1000,seed=800733088)[[1]]
 toc <- Sys.time()
 print(toc-tic)
@ 

Fig.~\ref{fig:ou_process} plots the data.

\begin{figure}
<<fig=T>>=
  plot(ou2)
@ 
  \caption{One realization of the two-dimensional OU process.}
  \label{fig:ou_process}
\end{figure}

The \code{pomp} object we just created is included in the package: use \code{data(ou2)} to retrieve it.
<<echo=F>>=
save(list='ou2',file='ou2.rda')
@ 

\section{Particle filter.}

We can run a particle filter as follows:
<<>>=
fit1 <- pfilter(ou2,params=p,Np=1000,filter.mean=T,pred.mean=T,pred.var=T)
@ 
Since \code{ou2} already contained the parameters \code{p}, it wasn't necessary to specify them;
we could have done
<<eval=F>>=
fit1 <- pfilter(ou2,Np=1000)
@
for example.
We can compare the results against those of the Kalman filter, which is exact in this case.
First, we need to implement the Kalman filter.
<<>>=
kalman.filter <- function (y, x0, a, b, sigma, tau) {
  n <- nrow(y)
  ntimes <- ncol(y)
  sigma.sq <- sigma%*%t(sigma)
  tau.sq <- tau%*%t(tau)
  inv.tau.sq <- solve(tau.sq)
  cond.dev <- numeric(ntimes)
  filter.mean <- matrix(0,n,ntimes)
  pred.mean <- matrix(0,n,ntimes)
  pred.var <- array(0,dim=c(n,n,ntimes))
  dev <- 0
  m <- x0
  v <- diag(0,n)
  for (k in seq(length=ntimes)) {
    pred.mean[,k] <- M <- a%*%m
    pred.var[,,k] <- V <- a%*%v%*%t(a)+sigma.sq
    q <- b%*%V%*%t(b)+tau.sq
    r <- y[,k]-b%*%M
    cond.dev[k] <- n*log(2*pi)+log(det(q))+t(r)%*%solve(q,r)
    dev <- dev+cond.dev[k]
    q <- t(b)%*%inv.tau.sq%*%b+solve(V)
    v <- solve(q)
    filter.mean[,k] <- m <- v%*%(t(b)%*%inv.tau.sq%*%y[,k]+solve(V,M))
  }
  list(
       pred.mean=pred.mean,
       pred.var=pred.var,
       filter.mean=filter.mean,
       cond.loglik=-0.5*cond.dev,
       loglik=-0.5*dev
       )
}
@ 
Now we can run it on the example data we generated above.
<<>>=
y <- data.array(ou2)
a <- matrix(p[c('alpha.1','alpha.2','alpha.3','alpha.4')],2,2)
b <- diag(1,2)
sigma <- matrix(c(p['sigma.1'],p['sigma.2'],0,p['sigma.3']),2,2)
tau <- diag(p['tau'],2,2)
fit2 <- kalman.filter(y,x0,a,b,sigma,tau)
@ 
In this case, the Kalman filter gives us a log likelihood of \code{fit2\$loglik=}\Sexpr{round(fit2$loglik,1)}, while the particle filter gives us \code{fit1\$loglik=}\Sexpr{round(fit1$loglik,1)}.

\section{The MIF algorithm}

In order to use MIF, we need to specify the distribution of particles in the state-parameter space.
This distribution must be such that, when \code{sd=0}, all the particles are identical.
For this example, we'll just use the default particle distribution, which draws particles from a multivariate normal distribution.

We'll run MIF to maximize the likelihood over two of the parameters and the initial conditions.
We'll use 1000 particles, an exponential cooling factor of 0.95, and a fixed-lag smoother with lag 10 for the initial conditions.
<<>>=
  ou2 <- mif(ou2,Nmif=0,start=p,
             pars=c('alpha.1','alpha.4'),ivps=c('x1.0','x2.0'),
             rw.sd=c(
               x1.0=5,x2.0=5,
               alpha.1=0.1,alpha.2=0,alpha.3=0,alpha.4=0.1,
               sigma.1=0,sigma.2=0,sigma.3=0,
               tau=0
               ),
             alg.pars=list(
               Np=1000,
               var.factor=1,
               ic.lag=10,
               cooling.factor=0.95
               ),
             max.fail=100
             )
@ 
Just to make it interesting, we'll start far from the true parameter values:
<<>>=
coef(ou2,c('x1.0','x2.0','alpha.1','alpha.4')) <- c(45,-60,0.8,0.9)
tic <- Sys.time()
fit <- mif(ou2,Nmif=2,max.fail=100)
fit <- continue(fit,Nmif=78,max.fail=100)
toc <- Sys.time()
print(toc-tic)
coef(fit)
@
The log likelihood of the random-parameter model at the end of the mif iterations, which should be a rough approximation of that of the fixed-parameter model, is \code{logLik(fit)=}\Sexpr{round(logLik(fit),1)}.
To get the log likelihood of the fixed-parameter model (up to Monte Carlo error) we can use \code{pfilter}:
<<>>=
pfilter(fit)$loglik
@ 
We can diagnose convergence of the MIF algorithm using ``convergence plots'' (Fig.~\ref{fig:convplot}).

\begin{figure}
<<fig=T,echo=F>>=
op <- par(mfrow=c(3,1))
plot(conv.rec(fit,'loglik'),type='l')
plot(conv.rec(fit,'alpha.1'),type='l')
plot(conv.rec(fit,'alpha.4'),type='l')
par(op)
@ 
\caption{Convergence plots can be used to help diagnose convergence of the MIF algorithm.}
\label{fig:convplot}
\end{figure}

Like \code{pomp} objects, \code{mif} objects can be simulated (Fig.~\ref{fig:mifsim}).

\begin{figure}
<<fig=T>>=
plot(simulate(fit)[[1]])
@ 
\caption{\code{mif} objects can be simulated.}  
\label{fig:mifsim}
\end{figure}

\end{document}
